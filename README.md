# Audio Event Tagging 

Project for Automatic Speech Recognition course: build and analyzed models to classify audio into speech, music, nature sounds etc from Google Dataset AudioSet.

The models have been trained in a constrained environment in terms of RAM memory and GPU. Namely, it has been used either Google Colab or personal laptop.

The models implemented are:

+ SVM
+ BLSTM / BGRU
+ Transformers


The models classify three different classes:
+ Humans: human sounds such as shout, laught, and speech
+ Animals: sound generated by livestock, wild animals, and domestic animals.
+ Natural: sound generated by wind , thunderstorm, water, fire.


You first have to download each YouTube video and extract the features. The `src/utils/download_audio.py` can guide you through. 
We encourage you to try with more data, wider and deeper architecture and also using different features to use as input for the models.

If you have any questions feel free to contact us!



