{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1crIc9tWYpLq"
   },
   "source": [
    "# Support Vector Machine for Automatic Speech Recognition\n",
    "\n",
    "---\n",
    "https://www.kaggle.com/anmour/svm-using-mfcc-features\n",
    "\n",
    "https://towardsdatascience.com/support-vector-machines-explained-with-python-examples-cb65e8172c85 : example of SVM\n",
    "\n",
    "https://github.com/HareeshBahuleyan/music-genre-classification :code\n",
    "https://www.groundai.com/project/music-genre-classification-using-machine-learning-techniques/1 :theory\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kEzW3k0nY1KM"
   },
   "source": [
    "( https://link.springer.com/chapter/10.1007/978-3-540-71505-4_11 )\n",
    "Hidden Markov Models (HMMs) are, undoubtedly, the most employed core technique for Automatic Speech Recognition (ASR). Nevertheless, we are still far from achieving high-performance ASR systems.\n",
    "The SVMs are effective discriminative classifiers with several outstanding characteristics, namely: their solution is that with maximum margin; they are capable to deal with samples of a very higher dimensionality; and their convergence to the minimum of the associated cost function is guaranteed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kNrwP6A5b1N8"
   },
   "source": [
    "# Data preparation\n",
    "https://mycourses.aalto.fi/pluginfile.php/1155540/mod_resource/content/2/AudioEvents-presentation.pdf\n",
    "\n",
    "-Dataset: google audioset\n",
    "- n=number of classes chosen\n",
    "- script for download dataset:\n",
    "  -download video from youtube\n",
    "  -extract audio from the video\n",
    "  -cute the audio based on the start time and the end time of the audio events\n",
    "\n",
    "# Data preprocessing and featre extraction\n",
    "-for CNN: mel frequency spectogram\n",
    "-for the SVM: MFCC, deltas..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDykvhyDc2_g"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oETOjpNlAyHQ"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_5V7Xl3B0dI"
   },
   "source": [
    "#Data Preparation\n",
    "\n",
    "# Da Cambiare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    # plt.figure(figsize=(8,8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "def one_hot_encoder(true_labels, num_records, num_classes):\n",
    "    temp = np.array(true_labels[:num_records])\n",
    "    true_labels = np.zeros((num_records, num_classes))\n",
    "    true_labels[np.arange(num_records), temp] = 1\n",
    "    return true_labels\n",
    "\n",
    "def display_results(y_test, pred_probs, cm = True):\n",
    "    pred = np.argmax(pred_probs, axis=-1)\n",
    "    one_hot_true = one_hot_encoder(y_test, len(pred), len(label_dict))\n",
    "    print('Test Set Accuracy =  {0:.2f}'.format(accuracy_score(y_test, pred)))\n",
    "    print('Test Set F-score =  {0:.2f}'.format(f1_score(y_test, pred, average='macro')))\n",
    "    print('ROC AUC = {0:.3f}'.format(roc_auc_score(y_true=one_hot_true, y_score=pred_probs, average='macro')))\n",
    "    if cm:\n",
    "        plot_confusion_matrix(confusion_matrix(y_test, pred), classes=label_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kGsNQcuEB4vD"
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "svm_classifier = SVC(C=10000.0, probability = True, class_weight=cl_weight, kernel='rbf')\n",
    "svm_classifier.fit(x_train, y_train)\n",
    "\n",
    "# Predict\n",
    "pred_probs = svm_classifier.predict_proba(x_test)\n",
    "\n",
    "# Results\n",
    "display_results(y_test, pred_probs)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Audio Event Tagging.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
